<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild. We present a framework for generating novel views of scenes learned from diverse 2D scene image data captured in the wild.">
    <meta name="keywords" content="WildCAT3D, Novel View Synthesis, Multi-view Diffusion, Appearance Control">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild</title>

    <meta property="og:title" content="WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild" />
    <meta property="og:description"
        content="We present a framework for generating novel views of scenes learned from diverse 2D scene image data captured in the wild." />

    <meta property="twitter:card" content="summary" />
    <meta property="twitter:title" content="WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild" />
    <meta property="twitter:description"
        content="We present a framework for generating novel views of scenes learned from diverse 2D scene image data captured in the wild." />

    <!-- MathJax library -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
        async></script>



    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./styles.css">
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title">WildCAT3D: Appearance-Aware Multi-View Diffusion in the
                            Wild</h1>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="#">Morris Alper</a><sup>1*</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://d-novotny.github.io/">David Novotny</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="#">Filippos Kokkinos</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="#">Hadar Averbuch-Elor</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="#">Tom Monnier</a><sup>2</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors" style="margin-bottom: 10px;">
                            <span class="author-block"><sup>1</sup>Tel Aviv University</span> &nbsp;&nbsp;
                            <span class="author-block"><sup>2</sup>Meta AI</span> &nbsp;&nbsp;
                            <span class="author-block"><sup>3</sup>Cornell University</span>
                        </div>

                        <div class="is-size-6" style="margin-bottom: 20px;">
                            <span>*Work done while interning at Meta AI</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-primary">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a href="./videos/video_results_viewer.html" class="external-link button is-normal is-rounded interactive-button">
                                        <span class="icon">
                                            <i class="fas fa-play"></i>
                                        </span>
                                        <span>Video Results</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Teaser Video Section -->
    <section class="hero teaser" style="background: white; color: black;">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video class="teaser-video" autoplay muted loop playsinline>
                    <source src="./resources/teaser_video.mp4" type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered" style="margin-top: 1rem; color: #666;">
                    WildCAT3D generates consistent novel views from single images while enabling appearance control
                </h2>
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-full-width has-text-centered">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Despite recent advances in sparse novel view synthesis (NVS) applied to object-centric
                            scenes, scene-level NVS remains a challenge. A central issue is the lack of available clean
                            multi-view training data, beyond manually curated datasets with limited diversity, camera
                            variation, or licensing issues. On the other hand, an abundance of diverse and
                            permissively-licensed data exists in the wild, consisting of scenes with varying appearances
                            (illuminations, transient occlusions, etc.) from sources such as tourist photos.
                            To this end, we present <strong>WildCAT3D</strong>, a framework for generating novel views
                            of scenes learned from diverse 2D scene image data captured in the wild. We unlock training
                            on these data sources by explicitly modeling global appearance conditions in images,
                            extending the state-of-the-art multi-view diffusion paradigm to learn from scene views of
                            varying appearances. Our trained model generalizes to new scenes at inference time, enabling
                            the generation of multiple consistent novel views.
                            WildCAT3D provides state-of-the-art results on single-view NVS in object- and scene-level
                            settings, while training on strictly less data sources than prior methods. Additionally, it
                            enables novel applications by providing global appearance control during generation.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Method Section -->
    <section class="section" style="background: #f8f9fa;">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-full-width has-text-centered">
                    <h2 class="title is-3">Method</h2>
                    <div class="content has-text-justified">
                        <p>
                            Our key insight is that inconsistent data can be leveraged during multi-view diffusion
                            training to learn consistent generation, by specifically decoupling content and appearance
                            when denoising novel views. Starting from the multi-view diffusion framework, we propose to
                            explicitly integrate a feed-forward appearance model that captures the appearance properties
                            of input views.
                        </p>
                        <p>
                            We add an appearance encoding branch to produce low-dimensional appearance embeddings used
                            as conditioning signals for the multi-view diffusion model. Additionally, we employ a warp
                            conditioning mechanism that warps pixels from the source view following the target viewpoint
                            using depth information, helping resolve scale ambiguity inherent to single-view NVS.
                        </p>
                    </div>
                    <div class="content has-text-centered">
                        <img class="method-diagram" src="./resources/method_diagram.png"
                            alt="WildCAT3D Method Overview">
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Appearance Control Section -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="appearance-control">
                <h2 class="title is-3 has-text-centered">Novel Appearance Control</h2>
                <div class="content has-text-centered">
                    <p style="font-size: 1.2rem; margin-bottom: 2rem;">
                        Our explicit modeling of appearance enables novel applications such as text-controlled
                        appearance generation and interpolation between different appearance conditions.
                    </p>
                    <div class="results-grid">
                        <div class="result-item">
                            <img src="./resources/appearance_control_1.jpg" alt="Sunny to Rainy">
                            <div class="content">
                                <h4>Weather Control</h4>
                                <p>Generate the same scene under different weather conditions</p>
                            </div>
                        </div>
                        <div class="result-item">
                            <img src="./resources/appearance_control_2.jpg" alt="Day to Night">
                            <div class="content">
                                <h4>Lighting Control</h4>
                                <p>Transform between day and night appearances</p>
                            </div>
                        </div>
                        <div class="result-item">
                            <img src="./resources/appearance_control_3.jpg" alt="Season Control">
                            <div class="content">
                                <h4>Seasonal Control</h4>
                                <p>Change seasonal appearance while maintaining geometry</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-full-width has-text-centered">
                    <h2 class="title is-3">Results</h2>
                    <div class="content has-text-justified">
                        <p>
                            WildCAT3D demonstrates superior performance on standard NVS benchmarks while training on
                            diverse in-the-wild data. Our method excels at generating consistent novel views for both
                            object-centric and scene-level scenarios.
                        </p>
                    </div>

                    <div class="results-grid">
                        <div class="result-item">
                            <video autoplay muted loop playsinline>
                                <source src="./resources/result_1.mp4" type="video/mp4">
                            </video>
                            <div class="content">
                                <h4>Tourist Photo Reconstruction</h4>
                                <p>Novel views generated from single tourist photos</p>
                            </div>
                        </div>
                        <div class="result-item">
                            <video autoplay muted loop playsinline>
                                <source src="./resources/result_2.mp4" type="video/mp4">
                            </video>
                            <div class="content">
                                <h4>Architectural Scenes</h4>
                                <p>Consistent view synthesis for complex architectural structures</p>
                            </div>
                        </div>
                        <div class="result-item">
                            <video autoplay muted loop playsinline>
                                <source src="./resources/result_3.mp4" type="video/mp4">
                            </video>
                            <div class="content">
                                <h4>Natural Landscapes</h4>
                                <p>High-quality novel views of natural outdoor scenes</p>
                            </div>
                        </div>
                        <div class="result-item">
                            <video autoplay muted loop playsinline>
                                <source src="./resources/result_4.mp4" type="video/mp4">
                            </video>
                            <div class="content">
                                <h4>Urban Environments</h4>
                                <p>Robust performance on complex urban scenes</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Comparison Section -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="comparison-section">
                <h2 class="title is-3 has-text-centered">Comparison with Prior Work</h2>
                <div class="content has-text-justified">
                    <p>
                        WildCAT3D outperforms existing methods on single-view novel view synthesis benchmarks, achieving
                        superior quality while training on more diverse but less curated data sources. Our approach
                        demonstrates particular strength in handling real-world scenes with varying appearances.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <img src="./resources/comparison_table.png" alt="Quantitative Comparison"
                        style="max-width: 80%; border-radius: 8px;">
                </div>
            </div>
        </div>
    </section>

    <!-- BibTeX Section -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title is-3">BibTeX</h2>
            <pre style="background: #f5f5f5; padding: 1rem; border-radius: 8px;"><code>@article{alper2025wildcat3d,
  title={WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild},
  author={Alper, Morris and Novotny, David and Kokkinos, Filippos and Averbuch-Elor, Hadar and Monnier, Tom},
  journal={arXiv preprint},
  year={2025}
}</code></pre>
        </div>
    </section>

    <!-- Acknowledgements Section -->
    <section class="section" style="background: #f8f9fa;">
        <div class="container is-max-desktop content">
            <h2 class="title is-3">Acknowledgments</h2>
            <p>
                This work was sponsored by Meta AI. We thank Kush Jain and Keren Ganon for providing helpful feedback.
            </p>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This webpage template is adapted from <a
                                href="https://github.com/facebookresearch/vggt">VGGT</a> and <a
                                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
                            under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0
                                License</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>