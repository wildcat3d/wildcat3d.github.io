<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild. We present a framework for generating novel views of scenes learned from diverse 2D scene image data captured in the wild.">
    <meta name="keywords" content="WildCAT3D, Novel View Synthesis, Multi-view Diffusion, Appearance Control">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild</title>

    <!-- Open Graph -->
    <meta property="og:url" content="https://wildcat3d.github.io/" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild" />
    <meta property="og:description"
        content="We present a framework for generating novel views of scenes learned from diverse 2D scene image data captured in the wild." />
    <meta property="og:image" content="https://wildcat3d.github.io/images/icon.png" />
    <meta property="og:image:type" content="image/png" />
    <meta property="og:image:width" content="512" />
    <meta property="og:image:height" content="284" />
    <meta property="og:site_name" content="WildCAT3D" />

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:domain" content="wildcat3d.github.io" />
    <meta name="twitter:url" content="https://wildcat3d.github.io/" />
    <meta name="twitter:title" content="WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild" />
    <meta name="twitter:description"
        content="We present a framework for generating novel views of scenes learned from diverse 2D scene image data captured in the wild." />
    <meta name="twitter:image" content="https://wildcat3d.github.io/images/icon.png" />

    <!-- MathJax library
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
        async></script> -->

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./styles.css">
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title">WildCAT3D: Appearance-Aware Multi-View Diffusion in the
                            Wild</h1>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="http://morrisalp.github.io">Morris Alper</a><sup>1,2</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://d-novotny.github.io/">David Novotny</a><sup>2</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://www.fkokkinos.com">Filippos Kokkinos</a><sup>2</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://www.hadarelor.com">Hadar Averbuch-Elor</a><sup>3</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://tmonnier.com">Tom Monnier</a><sup>2</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors publication-authors-affiliation">
                            <span class="author-block"><sup>1</sup>Tel Aviv University</span> &nbsp;&nbsp;
                            <span class="author-block"><sup>2</sup>Meta AI</span> &nbsp;&nbsp;
                            <span class="author-block"><sup>3</sup>Cornell University</span>
                        </div>

                        <div class="is-size-4 publication-venue">
                            <strong>NeurIPS 2025</strong>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2506.13030" class="external-link button is-normal is-rounded is-primary">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a href="./videos/video_results_viewer.html"
                                        class="external-link button is-normal is-rounded interactive-button">
                                        <span class="icon">
                                            <i class="fas fa-play"></i>
                                        </span>
                                        <span>Video Results</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <div class="columns is-centered is-variable is-6 is-multiline teaser-grid">

                    <!-- Top: Training data collage -->
                    <div class="column is-12 has-text-centered">
                        <img src="./images/wild_training_collage.jpg"
                            alt="Training data: collage of scene images under varying conditions"
                            class="train-collage-img">
                        <p class="mt-2">
                            <strong>Training:</strong> Internet image collections captured <em>in-the-wild</em>.
                        </p>
                    </div>

                    <!-- Input + Output row wrapped for centering -->
                    <div class="columns is-centered is-variable is-6">
                        <div class="column is-4 has-text-centered">
                            <img src="./videos/inference/images-014-126-commons-Pont_de_la_Caille-0-pictures/gt0.png"
                                alt="Input view (single image)" class="io-img">
                            <p><strong>Input (Single View)</strong></p>
                        </div>
                        <div class="column is-4 has-text-centered">
                            <img src="./videos/inference/images-014-126-commons-Pont_de_la_Caille-0-pictures/gen0.gif"
                                alt="Generated novel views from WildCAT3D" class="io-img">
                            <p><strong>Output (Novel Consistent Views)</strong></p>
                        </div>
                    </div>

                </div>

                <!-- Subtitle -->
                <h2 class="subtitle has-text-centered teaser-subtitle mt-4">
                    WildCAT3D learns from in-the-wild image collections with diverse appearances, enabling consistent
                    novel view synthesis from a single image capturing a never-before-seen scene.
                </h2>
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-full-width has-text-centered">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Despite recent advances in sparse novel view synthesis (NVS) applied to object-centric
                            scenes, scene-level NVS remains a challenge. A central issue is the lack of available clean
                            multi-view training data, beyond manually curated datasets with limited diversity, camera
                            variation, or licensing issues. On the other hand, an abundance of diverse and
                            permissively-licensed data exists in the wild, consisting of scenes with varying appearances
                            (illuminations, transient occlusions, etc.) from sources such as tourist photos.
                            To this end, we present <strong>WildCAT3D</strong>, a framework for generating novel views
                            of scenes learned from diverse 2D scene image data captured in the wild. We unlock training
                            on these data sources by explicitly modeling global appearance conditions in images,
                            extending the state-of-the-art multi-view diffusion paradigm to learn from scene views of
                            varying appearances. Our trained model generalizes to new scenes at inference time, enabling
                            the generation of multiple consistent novel views.
                            WildCAT3D provides state-of-the-art results on single-view NVS in object- and scene-level
                            settings, while training on strictly less data sources than prior methods. Additionally, it
                            enables novel applications by providing global appearance control during generation.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Method Section -->
    <section class="section section-alt-bg">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-full-width has-text-centered">
                    <h2 class="title is-3">Method</h2>
                    <div class="content has-text-justified">
                        <p>
                            Our key insight is that inconsistent data can be leveraged during multi-view diffusion
                            training to learn consistent generation, by specifically decoupling content and appearance
                            when denoising novel views. Starting from a multi-view diffusion framework, we propose to
                            explicitly integrate a feed-forward, generalizeable appearance encoder that models
                            appearance
                            variations between scene views.
                            We add an appearance encoding branch to produce low-dimensional appearance embeddings used
                            as conditioning signals for the multi-view diffusion model. Additionally, we employ a warp
                            conditioning mechanism to resolve the scale ambiguity inherent to single-view NVS.
                        </p>
                    </div>
                    <div class="content has-text-centered">
                        <img class="method-diagram" src="./images/system.jpg" alt="WildCAT3D Method Overview">
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Comparison Section -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="comparison-section">
                <h2 class="title is-3 has-text-centered">Results and Comparison</h2>
                <div class="content has-text-justified">
                    <p>
                        WildCAT3D significantly outperforms the previous SOTA MegaScenes NVS model (MS NVS) at
                        generating consistent and high-quality novel view sequences from single images. Our method
                        achieves superior performance while training on unfiltered data in-the-wild, unlike the
                        aggressive filtering
                        used by prior methods.
                    </p>
                </div>
                <div class="comparison-videos">
                    <div class="comparison-item">
                        <h4 class="title is-5">MS NVS</h4>
                        <img src="./videos/comparisons/gavi_ms.gif" alt="MS NVS result">
                    </div>
                    <div class="comparison-item good-comparison-item">
                        <h4 class="title is-5">Ours</h4>
                        <img src="./videos/comparisons/gavi_ours.gif" alt="Our result">
                    </div>
                    <div class="comparison-item">
                        <h4 class="title is-5">MS NVS</h4>
                        <img src="./videos/comparisons/wawel_ms.gif" alt="MS NVS result">
                    </div>
                    <div class="comparison-item good-comparison-item">
                        <h4 class="title is-5">Ours</h4>
                        <img src="./videos/comparisons/wawel_ours.gif" alt="Our result">
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Applications Section -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="appearance-control">
                <h2 class="title is-3 has-text-centered">Applications</h2>
                <div class="content has-text-centered">
                    <p class="appearance-control-text">
                        Our explicit modeling of appearance enables novel applications such as appearance-controlled
                        generation
                        using external conditioning images and interpolation between views of differing appearances.
                    </p>

                    <!-- Appearance Control -->
                    <div class="application-demo">
                        <h4 class="title is-4">Appearance-Controlled Generation</h4>
                        <div class="demo-row">
                            <div class="demo-item">
                                <img src="./videos/applications/appearance_conditioned_gen/5_gt.png" alt="Input view">
                                <p>Input View</p>
                            </div>
                            <div class="demo-item">
                                <img src="./videos/applications/appearance_conditioned_gen/5_appearance.png"
                                    alt="Appearance condition">
                                <p>Appearance Condition</p>
                            </div>
                            <div class="demo-item">
                                <img src="./videos/applications/appearance_conditioned_gen/5_gen.gif"
                                    alt="Generated result">
                                <p>Generated Novel Views</p>
                            </div>
                        </div>
                    </div>

                    <!-- Interpolation -->
                    <div class="application-demo">
                        <h4 class="title is-4">In-the-Wild Interpolation</h4>
                        <div class="demo-row">
                            <div class="demo-item">
                                <img src="./videos/applications/interpolation/5_start.png" alt="Start view">
                                <p>Start View</p>
                            </div>
                            <div class="demo-item">
                                <img src="./videos/applications/interpolation/5_interp.gif"
                                    alt="Generated interpolation sequence">
                                <p>Generated Interpolation Sequence</p>
                            </div>
                            <div class="demo-item">
                                <img src="./videos/applications/interpolation/5_end.png" alt="End view">
                                <p>End View</p>
                            </div>
                        </div>
                    </div>

                    <p class="additional-results-text">
                        <a href="videos/video_results_viewer.html">Click here</a> for additional results.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- BibTeX Section -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title is-3">BibTeX</h2>
            <pre class="bibtex-code"><code>@InProceedings{alper2025wildcat3d,
  title={WildCAT3D: Appearance-Aware Multi-View Diffusion in the Wild},
  author={Alper, Morris and Novotny, David and Kokkinos, Filippos and Averbuch-Elor, Hadar and Monnier, Tom},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NeurIPS)},
  year={2025}
}</code></pre>
        </div>
    </section>

    <!-- Acknowledgements Section -->
    <section class="section section-alt-bg">
        <div class="container is-max-desktop content">
            <h2 class="title is-3">Acknowledgments</h2>
            <p>
                This work was sponsored by Meta AI. We thank Kush Jain and Keren Ganon for providing helpful feedback.
            </p>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This webpage template is adapted from <a
                                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
                            under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0
                                License</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>